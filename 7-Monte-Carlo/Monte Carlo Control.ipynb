{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_SPACE = ('U', 'D', 'L', 'R')\n",
    "class gridWorld:\n",
    "    \n",
    "    def __init__(self,rows,cols,startPosition):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.i = startPosition[0]\n",
    "        self.j = startPosition[1]\n",
    "        \n",
    "    \n",
    "    def setOnGrid(self,rewards,actions):\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "    \n",
    "    def setState(self,s):\n",
    "        self.i = s[0]\n",
    "        self.j = s[1]\n",
    "    \n",
    "    def move(self,a):\n",
    "        if a in self.actions[self.i,self.j] :\n",
    "            if a =='U':\n",
    "                self.i -= 1\n",
    "            elif a =='D':\n",
    "                self.i += 1\n",
    "            elif a == 'L':\n",
    "                self.j -= 1\n",
    "            elif a == 'R':\n",
    "                self.j += 1\n",
    "        return self.rewards.get((self.i,self.j),0)\n",
    "    \n",
    "    def getNextState(self,s,a):\n",
    "        i,j = s[0],s[1]\n",
    "        \n",
    "        if a in self.actions[(i,j)]:\n",
    "            if a =='U':\n",
    "                i -= 1\n",
    "            elif a =='D':\n",
    "                i += 1\n",
    "            elif a == 'L':\n",
    "                j -= 1\n",
    "            elif a == 'R':\n",
    "                j += 1\n",
    "        return i,j\n",
    "                \n",
    "    def allStates(self):\n",
    "        return set(self.actions.keys()) | set(self.rewards.keys())\n",
    "        \n",
    "    def allActions(self):\n",
    "        return np.array(['U','D','L','R'])\n",
    "    \n",
    "    def currentState(self):\n",
    "        return (self.i,self.j)\n",
    "    \n",
    "    def isTerminal(self,s):\n",
    "        return s not in self.actions\n",
    "    \n",
    "    def reset(self):\n",
    "        self.i = 2\n",
    "        self.j = 0\n",
    "        return (self.i,self.j)\n",
    "    \n",
    "    def gameOver(self):\n",
    "        return (self.i, self.j) not in self.actions\n",
    "            \n",
    "    \n",
    "def standardGrid():\n",
    "    g = gridWorld(2+1,3+1,(2,0))\n",
    "    rewards = {(0,3): +1 ,(1,3): -1}\n",
    "    actions = {\n",
    "        (0, 0): ('D', 'R'),\n",
    "        (0, 1): ('L', 'R'),\n",
    "        (0, 2): ('L', 'D', 'R'),\n",
    "        (1, 0): ('U', 'D'),\n",
    "        (1, 2): ('U', 'D', 'R'),\n",
    "        (2, 0): ('U', 'R'),\n",
    "        (2, 1): ('L', 'R'),\n",
    "        (2, 2): ('L', 'R', 'U'),\n",
    "        (2, 3): ('L', 'U'),\n",
    "    }\n",
    "    g.setOnGrid(rewards,actions)\n",
    "    return g\n",
    "\n",
    "def negativeGrid():\n",
    "    g = standardGrid()\n",
    "    g.rewards.update({\n",
    "        (0, 0): step_cost,\n",
    "        (0, 1): step_cost,\n",
    "        (0, 2): step_cost,\n",
    "        (1, 0): step_cost,\n",
    "        (1, 2): step_cost,\n",
    "        (2, 0): step_cost,\n",
    "        (2, 1): step_cost,\n",
    "        (2, 2): step_cost,\n",
    "        (2, 3): step_cost,\n",
    "    })\n",
    "    return g\n",
    "\n",
    "def printPolicy(P, g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.cols):\n",
    "            a = P.get((i,j), ' ')\n",
    "            print(\"  %s  |\" % a, end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "def printValues(V, g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.cols):\n",
    "            v = V.get((i,j), 0)\n",
    "            if v >= 0:\n",
    "                print(\" %.2f|\" % v, end=\"\")\n",
    "            else:\n",
    "                print(\"%.2f|\" % v, end=\"\")\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playGame(grid , policy , max_steps = 20):\n",
    "    start_states = list (grid.actions.keys())\n",
    "    start_idx = np.random.choice(len(start_states))\n",
    "    grid.setState(start_states[start_idx])\n",
    "    \n",
    "    a = np.random.choice(ACTION_SPACE)\n",
    "    s = grid.currentState()\n",
    "    states = [s]\n",
    "    actions = [a]\n",
    "    rewards = [0]\n",
    "    \n",
    "    steps = 0\n",
    "    for _ in range(max_steps):\n",
    "        r = grid.move(a)\n",
    "        s = grid.currentState()\n",
    "\n",
    "        rewards.append(r)\n",
    "        states.append(s)\n",
    "    \n",
    "        if grid.gameOver():\n",
    "            break\n",
    "        else:\n",
    "            a = policy[s]\n",
    "            actions.append(a)\n",
    "    \n",
    "    return states,actions,rewards\n",
    "\n",
    "\n",
    "def max_dict(d):\n",
    "  # returns the argmax (key) and max (value) from a dictionary\n",
    "  # put this into a function since we are using it so often\n",
    "\n",
    "  # find max val\n",
    "  max_val = max(d.values())\n",
    "\n",
    "  # find keys corresponding to max val\n",
    "  max_keys = [key for key, val in d.items() if val == max_val]\n",
    "\n",
    "  ### slow version\n",
    "  # max_keys = []\n",
    "  # for key, val in d.items():\n",
    "  #   if val == max_val:\n",
    "  #     max_keys.append(key)\n",
    "\n",
    "  return np.random.choice(max_keys), max_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n",
      "final values:\n",
      "---------------------------\n",
      " 0.81| 0.90| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.73| 0.00| 0.90| 0.00|\n",
      "---------------------------\n",
      " 0.66| 0.73| 0.81| 0.73|\n"
     ]
    }
   ],
   "source": [
    "grid = standardGrid()\n",
    "policy = {}\n",
    "Q = {}\n",
    "sample_counts = {}\n",
    "for s in grid.actions.keys():\n",
    "    policy[s] = np.random.choice(ACTION_SPACE)\n",
    "for s in grid.allStates():\n",
    "    if s in grid.actions:\n",
    "        Q[s] = {}\n",
    "        sample_counts[s] = {}\n",
    "        for a in ACTION_SPACE:\n",
    "            Q[s][a] = 0\n",
    "            sample_counts[s][a] = 0\n",
    "    else:\n",
    "        pass\n",
    "#start_s = list(policy)[np.random.choice(len(policy))\n",
    "gamma = 0.9\n",
    "deltas = []\n",
    "for _ in range(10000):\n",
    "    delta = 0\n",
    "    states,actions,rewards = playGame(grid,policy)\n",
    "    \n",
    "    states_actions = list(zip(states, actions))\n",
    "    G = 0 \n",
    "    T = len(states)\n",
    "    for t in range(T-2,-1,-1):\n",
    "        s = states[t]\n",
    "        a = actions[t]\n",
    "        G = rewards[t+1] + gamma * G\n",
    "        if (s,a) not in  states_actions[:t]:\n",
    "            old_q = Q[s][a]\n",
    "            sample_counts[s][a] += 1\n",
    "            lr = 1/sample_counts[s][a]\n",
    "            Q[s][a] = old_q + lr * (G-old_q)\n",
    "            #policy[s] = list(Q[s])[np.argmax(list(Q[s].values()))]\n",
    "            policy[s] = max_dict(Q[s])[0]\n",
    "            delta = max (delta,np.abs(old_q - Q[s][a]))\n",
    "    deltas.append(delta)\n",
    "plt.plot(deltas)\n",
    "plt.show()\n",
    "print(\"final policy:\")\n",
    "printPolicy(policy, grid)\n",
    "\n",
    "  # find V\n",
    "V = {}\n",
    "for s, Qs in Q.items():\n",
    "    V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "print(\"final values:\")\n",
    "printValues(V, grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
